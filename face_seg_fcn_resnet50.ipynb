{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "mount_file_id": "1ERMcu_Q10fyNLq9v4rx4KQAlhWJHVcPk",
      "authorship_tag": "ABX9TyN7O+2Zf2BaO2a3LWz4M4a6",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/jmbmartins/Human-Recognition-in-Surveillance-Settings/blob/main/face_seg_fcn_resnet50.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import cv2\n",
        "import torch\n",
        "from PIL import Image\n",
        "import torchvision.transforms as transforms\n",
        "from torchvision import models\n",
        "import numpy as np\n",
        "\n",
        "print(\"Loading the pretrained model...\")\n",
        "model = models.segmentation.fcn_resnet50(pretrained=True)\n",
        "model.eval()\n",
        "\n",
        "transform = transforms.Compose([\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n",
        "])\n",
        "\n",
        "input_dir = \"/content/drive/MyDrive/Computer Vision/Projeto/heads_square\"\n",
        "output_dir = \"/content/drive/MyDrive/Computer Vision/Projeto/segmented_images\"\n",
        "\n",
        "print(f\"Starting to process images in {input_dir}...\")\n",
        "for dirpath, dirnames, filenames in os.walk(input_dir):\n",
        "    relative_path = os.path.relpath(dirpath, input_dir)\n",
        "    output_path_dir = os.path.join(output_dir, relative_path)\n",
        "\n",
        "    # Check if this directory has already been processed\n",
        "    if os.path.exists(output_path_dir):\n",
        "        print(f\"Skipping {dirpath} as it has already been processed.\")\n",
        "        continue\n",
        "\n",
        "    for filename in filenames:\n",
        "        if filename.endswith('.jpg'):\n",
        "            input_path = os.path.join(dirpath, filename)\n",
        "\n",
        "            img = Image.open(input_path)\n",
        "            img_transformed = transform(img)\n",
        "            img_transformed = img_transformed.unsqueeze(0)\n",
        "\n",
        "            out = model(img_transformed)['out']\n",
        "            parsing = out.detach().squeeze(0).cpu().numpy().argmax(0)\n",
        "\n",
        "            original_img = cv2.imread(input_path)\n",
        "            green_img = np.zeros(original_img.shape, dtype=np.uint8)\n",
        "            green_img[:] = [0, 255, 0]  # Set all pixels to green\n",
        "\n",
        "            mask = parsing != 0\n",
        "\n",
        "            original_img = cv2.imread(input_path)\n",
        "\n",
        "            green_img[mask] = original_img[mask]\n",
        "\n",
        "            output_path = os.path.join(output_path_dir, filename)\n",
        "\n",
        "            os.makedirs(os.path.dirname(output_path), exist_ok=True)\n",
        "\n",
        "            cv2.imwrite(output_path, green_img)\n",
        "\n",
        "    print(f\"Finished processing images in {dirpath}.\")\n",
        "\n",
        "print(\"Finished processing all images.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "pmnzNqjMp4Ed",
        "outputId": "66d91536-2236-4231-8d3c-8c97f8871f7b"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loading the pretrained model...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=FCN_ResNet50_Weights.COCO_WITH_VOC_LABELS_V1`. You can also use `weights=FCN_ResNet50_Weights.DEFAULT` to get the most up-to-date weights.\n",
            "  warnings.warn(msg)\n",
            "Downloading: \"https://download.pytorch.org/models/fcn_resnet50_coco-1167a1af.pth\" to /root/.cache/torch/hub/checkpoints/fcn_resnet50_coco-1167a1af.pth\n",
            "100%|██████████| 135M/135M [00:00<00:00, 148MB/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Starting to process images in /content/drive/MyDrive/Computer Vision/Projeto/heads_square...\n",
            "Skipping /content/drive/MyDrive/Computer Vision/Projeto/heads_square as it has already been processed.\n",
            "Skipping /content/drive/MyDrive/Computer Vision/Projeto/heads_square/036_E_1 as it has already been processed.\n",
            "Skipping /content/drive/MyDrive/Computer Vision/Projeto/heads_square/036_E_2 as it has already been processed.\n",
            "Skipping /content/drive/MyDrive/Computer Vision/Projeto/heads_square/036_U_1 as it has already been processed.\n",
            "Skipping /content/drive/MyDrive/Computer Vision/Projeto/heads_square/036_U_2 as it has already been processed.\n",
            "Skipping /content/drive/MyDrive/Computer Vision/Projeto/heads_square/037_E_1 as it has already been processed.\n",
            "Skipping /content/drive/MyDrive/Computer Vision/Projeto/heads_square/037_E_2 as it has already been processed.\n",
            "Skipping /content/drive/MyDrive/Computer Vision/Projeto/heads_square/037_U_1 as it has already been processed.\n",
            "Skipping /content/drive/MyDrive/Computer Vision/Projeto/heads_square/037_U_2 as it has already been processed.\n",
            "Skipping /content/drive/MyDrive/Computer Vision/Projeto/heads_square/038_E_1 as it has already been processed.\n",
            "Skipping /content/drive/MyDrive/Computer Vision/Projeto/heads_square/038_E_2 as it has already been processed.\n",
            "Skipping /content/drive/MyDrive/Computer Vision/Projeto/heads_square/038_U_1 as it has already been processed.\n",
            "Skipping /content/drive/MyDrive/Computer Vision/Projeto/heads_square/038_U_2 as it has already been processed.\n",
            "Skipping /content/drive/MyDrive/Computer Vision/Projeto/heads_square/039_E_1 as it has already been processed.\n",
            "Skipping /content/drive/MyDrive/Computer Vision/Projeto/heads_square/039_E_2 as it has already been processed.\n",
            "Skipping /content/drive/MyDrive/Computer Vision/Projeto/heads_square/039_U_1 as it has already been processed.\n",
            "Skipping /content/drive/MyDrive/Computer Vision/Projeto/heads_square/039_U_2 as it has already been processed.\n",
            "Skipping /content/drive/MyDrive/Computer Vision/Projeto/heads_square/040_E_1 as it has already been processed.\n",
            "Skipping /content/drive/MyDrive/Computer Vision/Projeto/heads_square/040_E_2 as it has already been processed.\n",
            "Skipping /content/drive/MyDrive/Computer Vision/Projeto/heads_square/040_U_1 as it has already been processed.\n",
            "Skipping /content/drive/MyDrive/Computer Vision/Projeto/heads_square/040_U_2 as it has already been processed.\n",
            "Skipping /content/drive/MyDrive/Computer Vision/Projeto/heads_square/041_E_1 as it has already been processed.\n",
            "Skipping /content/drive/MyDrive/Computer Vision/Projeto/heads_square/041_E_2 as it has already been processed.\n",
            "Skipping /content/drive/MyDrive/Computer Vision/Projeto/heads_square/041_U_1 as it has already been processed.\n",
            "Skipping /content/drive/MyDrive/Computer Vision/Projeto/heads_square/041_U_2 as it has already been processed.\n",
            "Skipping /content/drive/MyDrive/Computer Vision/Projeto/heads_square/042_E_1 as it has already been processed.\n",
            "Skipping /content/drive/MyDrive/Computer Vision/Projeto/heads_square/042_E_2 as it has already been processed.\n",
            "Skipping /content/drive/MyDrive/Computer Vision/Projeto/heads_square/042_U_1 as it has already been processed.\n",
            "Skipping /content/drive/MyDrive/Computer Vision/Projeto/heads_square/042_U_2 as it has already been processed.\n",
            "Skipping /content/drive/MyDrive/Computer Vision/Projeto/heads_square/043_E_1 as it has already been processed.\n",
            "Skipping /content/drive/MyDrive/Computer Vision/Projeto/heads_square/043_E_2 as it has already been processed.\n",
            "Skipping /content/drive/MyDrive/Computer Vision/Projeto/heads_square/043_U_1 as it has already been processed.\n",
            "Finished processing images in /content/drive/MyDrive/Computer Vision/Projeto/heads_square/043_U_2.\n",
            "Finished processing images in /content/drive/MyDrive/Computer Vision/Projeto/heads_square/044_E_1.\n",
            "Finished processing images in /content/drive/MyDrive/Computer Vision/Projeto/heads_square/044_E_2.\n",
            "Finished processing images in /content/drive/MyDrive/Computer Vision/Projeto/heads_square/044_U_1.\n",
            "Finished processing images in /content/drive/MyDrive/Computer Vision/Projeto/heads_square/044_U_2.\n",
            "Finished processing images in /content/drive/MyDrive/Computer Vision/Projeto/heads_square/045_E_1.\n",
            "Finished processing images in /content/drive/MyDrive/Computer Vision/Projeto/heads_square/045_E_2.\n",
            "Finished processing images in /content/drive/MyDrive/Computer Vision/Projeto/heads_square/045_U_1.\n",
            "Finished processing images in /content/drive/MyDrive/Computer Vision/Projeto/heads_square/045_U_2.\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-1-cdc9658ded02>\u001b[0m in \u001b[0;36m<cell line: 22>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     40\u001b[0m             \u001b[0mparsing\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mout\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdetach\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msqueeze\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcpu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnumpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     41\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 42\u001b[0;31m             \u001b[0moriginal_img\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcv2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mimread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_path\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     43\u001b[0m             \u001b[0mgreen_img\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzeros\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moriginal_img\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0muint8\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     44\u001b[0m             \u001b[0mgreen_img\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m255\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m  \u001b[0;31m# Set all pixels to green\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    }
  ]
}